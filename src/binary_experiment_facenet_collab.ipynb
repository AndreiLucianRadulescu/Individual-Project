{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2cf2fbaea71949bd927a19827d15b990": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cbb0af92f68b4e1199a0b45461a3971e",
              "IPY_MODEL_fb5f727b33824b36b0e0a2f992476ac2",
              "IPY_MODEL_65751edfaa674eba9d65ab1053979ada"
            ],
            "layout": "IPY_MODEL_fa2e735205314513b92cba174e9ef26d"
          }
        },
        "cbb0af92f68b4e1199a0b45461a3971e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cbea868f474c43fd8cf4b286515af143",
            "placeholder": "​",
            "style": "IPY_MODEL_a4d6e2051da5419b8f8f1b2eaa9f2d8b",
            "value": "100%"
          }
        },
        "fb5f727b33824b36b0e0a2f992476ac2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05060865dc8641ccb35a56222c54cfff",
            "max": 111898327,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4012dcaec1e4495ca1c0663bba916580",
            "value": 111898327
          }
        },
        "65751edfaa674eba9d65ab1053979ada": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02bc43624a6f464da519d14b1e122bca",
            "placeholder": "​",
            "style": "IPY_MODEL_43069b42f6a04baba3113e5965f377c7",
            "value": " 107M/107M [00:00&lt;00:00, 346MB/s]"
          }
        },
        "fa2e735205314513b92cba174e9ef26d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbea868f474c43fd8cf4b286515af143": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4d6e2051da5419b8f8f1b2eaa9f2d8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "05060865dc8641ccb35a56222c54cfff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4012dcaec1e4495ca1c0663bba916580": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "02bc43624a6f464da519d14b1e122bca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43069b42f6a04baba3113e5965f377c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSGNTkztE6ti",
        "outputId": "bf6f8ecb-9c85-4258-ab4f-0666fc7f44ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)\n",
        "drive_dir = '/content/drive/MyDrive'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install facenet-pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzraYzVVFGfz",
        "outputId": "8461ae58-367b-4af5-84ad-e2d2f98c6176"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting facenet-pytorch\n",
            "  Downloading facenet_pytorch-2.5.3-py3-none-any.whl (1.9 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.9 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.4/1.9 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from facenet-pytorch) (1.25.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from facenet-pytorch) (2.31.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from facenet-pytorch) (0.17.1+cu121)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from facenet-pytorch) (9.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->facenet-pytorch) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->facenet-pytorch) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->facenet-pytorch) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->facenet-pytorch) (2024.2.2)\n",
            "Requirement already satisfied: torch==2.2.1 in /usr/local/lib/python3.10/dist-packages (from torchvision->facenet-pytorch) (2.2.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision->facenet-pytorch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision->facenet-pytorch) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision->facenet-pytorch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision->facenet-pytorch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision->facenet-pytorch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision->facenet-pytorch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.2.1->torchvision->facenet-pytorch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m67.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.2.1->torchvision->facenet-pytorch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m68.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.2.1->torchvision->facenet-pytorch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m97.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.2.1->torchvision->facenet-pytorch)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.2.1->torchvision->facenet-pytorch)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.2.1->torchvision->facenet-pytorch)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch==2.2.1->torchvision->facenet-pytorch)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.2.1->torchvision->facenet-pytorch)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.2.1->torchvision->facenet-pytorch)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch==2.2.1->torchvision->facenet-pytorch)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch==2.2.1->torchvision->facenet-pytorch)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision->facenet-pytorch) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.1->torchvision->facenet-pytorch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m81.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.2.1->torchvision->facenet-pytorch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.2.1->torchvision->facenet-pytorch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, facenet-pytorch\n",
            "Successfully installed facenet-pytorch-2.5.3 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/\n",
        "!mkdir /content/data"
      ],
      "metadata": {
        "id": "aUu6jv3JFH4U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!!unrar x /content/drive/MyDrive/all_images.rar /content/data -idq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LgupG0uZFKWc",
        "outputId": "ad216d81-394e-4088-ed2b-a273dee9a4e9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import cv2\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.gridspec import GridSpec\n",
        "import pickle\n",
        "import random\n",
        "import json\n",
        "import time\n",
        "import os\n",
        "\n",
        "SEED = 42\n",
        "\n",
        "import torch\n",
        "import torchvision.transforms.functional as F\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torch.optim.lr_scheduler import OneCycleLR\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.models import resnet50, ResNet50_Weights\n",
        "\n",
        "# Set random seed for PyTorch\n",
        "torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(SEED)\n",
        "\n",
        "# Set random seed for NumPy\n",
        "np.random.seed(SEED)\n",
        "random.seed(42)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "base_dir = \"/content/data/all_images\""
      ],
      "metadata": {
        "id": "iH55COi8FZE2"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "\n",
        "class AgeDataset(Dataset):\n",
        "    # image_paths: list of image paths as strings\n",
        "    # labels: list of labels as integers\n",
        "    # resize: (channels, width, height) new image shape\n",
        "    def __init__(self, image_paths, labels, resize=None, augmentations=None):\n",
        "        self.num_samples = len(image_paths)\n",
        "        self.image_paths = image_paths\n",
        "        self.transform = augmentations\n",
        "        self.labels = labels\n",
        "\n",
        "        self.resize = resize\n",
        "        if resize is not None:\n",
        "            resize = list(resize)\n",
        "            self.resize = [resize[x] for x in (1,2,0)]\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_samples\n",
        "\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        image = Image.open(self.image_paths[item])\n",
        "        image = image.convert(\"RGB\")\n",
        "        label = self.labels[item]\n",
        "\n",
        "        if self.resize is not None:\n",
        "            image = image.resize(\n",
        "                (self.resize[1], self.resize[0]), resample=Image.BILINEAR\n",
        "            )\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        else:\n",
        "            image = np.array(image)\n",
        "\n",
        "            # transpose from 32x32x3 to 3x32x32\n",
        "            image = np.transpose(image, (2, 0, 1)).astype(np.float32)\n",
        "            # image = image.permute()\n",
        "\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "lCNvHZEOFLt6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/age_intervals_binary.json') as f:\n",
        "  current_config = json.load(f)\n",
        "\n",
        "classes = [str(x) for x in current_config.values()]\n",
        "\n",
        "classes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Dzoi_8xFQjw",
        "outputId": "efabaf8b-4d13-4fb0-ae3a-1244189f7225"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[6, 17]', '[18, 120]']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/initial_splits_binary.json') as f:\n",
        "    initial_splits = json.load(f)\n",
        "\n",
        "with open('/content/drive/MyDrive/dataframe.pkl', 'rb') as f:\n",
        "    df = pickle.load(f)\n",
        "\n",
        "df = df.drop(columns=['hog_features'])\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5iOcoLOFU7z",
        "outputId": "680c4664-41f2-4084-8487-207f13925302"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                              name  age\n",
            "0                       000002.jpg   80\n",
            "1                       000003.jpg   50\n",
            "2                       000004.jpg   17\n",
            "3                       000005.jpg   27\n",
            "4                       000006.jpg   24\n",
            "...                            ...  ...\n",
            "26846  9_1_0_20170110224621441.jpg    9\n",
            "26847  9_1_0_20170117172655681.jpg    9\n",
            "26848  9_1_0_20170117180006484.jpg    9\n",
            "26849  9_1_1_20170109201837354.jpg    9\n",
            "26850  9_1_1_20170117105556810.jpg    9\n",
            "\n",
            "[26851 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def create_label_dict(config):\n",
        "    label_dict = {}\n",
        "    for label, age_interval in config.items():\n",
        "        age_interval = list(age_interval)\n",
        "        age_interval[1] += 1\n",
        "        for age in range(*age_interval):\n",
        "            label_dict[age] = int(label)\n",
        "\n",
        "    return label_dict\n",
        "\n",
        "age_to_label = create_label_dict(current_config)\n",
        "print(age_to_label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3oLoHGwSFdas",
        "outputId": "e5be8ff8-0f59-4fbc-b44b-a58c5fe26304"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{6: 0, 7: 0, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 1, 19: 1, 20: 1, 21: 1, 22: 1, 23: 1, 24: 1, 25: 1, 26: 1, 27: 1, 28: 1, 29: 1, 30: 1, 31: 1, 32: 1, 33: 1, 34: 1, 35: 1, 36: 1, 37: 1, 38: 1, 39: 1, 40: 1, 41: 1, 42: 1, 43: 1, 44: 1, 45: 1, 46: 1, 47: 1, 48: 1, 49: 1, 50: 1, 51: 1, 52: 1, 53: 1, 54: 1, 55: 1, 56: 1, 57: 1, 58: 1, 59: 1, 60: 1, 61: 1, 62: 1, 63: 1, 64: 1, 65: 1, 66: 1, 67: 1, 68: 1, 69: 1, 70: 1, 71: 1, 72: 1, 73: 1, 74: 1, 75: 1, 76: 1, 77: 1, 78: 1, 79: 1, 80: 1, 81: 1, 82: 1, 83: 1, 84: 1, 85: 1, 86: 1, 87: 1, 88: 1, 89: 1, 90: 1, 91: 1, 92: 1, 93: 1, 94: 1, 95: 1, 96: 1, 97: 1, 98: 1, 99: 1, 100: 1, 101: 1, 102: 1, 103: 1, 104: 1, 105: 1, 106: 1, 107: 1, 108: 1, 109: 1, 110: 1, 111: 1, 112: 1, 113: 1, 114: 1, 115: 1, 116: 1, 117: 1, 118: 1, 119: 1, 120: 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_indices = initial_splits['train']\n",
        "test_indices = initial_splits['test']\n",
        "\n",
        "X_train = [os.path.join(base_dir, df['name'][idx]) for idx in train_indices]\n",
        "y_train = [age_to_label[df['age'][idx]] for idx in train_indices]\n",
        "X_test = [os.path.join(base_dir, df['name'][idx]) for idx in test_indices]\n",
        "y_test = [age_to_label[df['age'][idx]] for idx in test_indices]"
      ],
      "metadata": {
        "id": "D2UegOFPFeYp"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RandomBoundingBoxJitter:\n",
        "    def __init__(self, magnitude=0.45):\n",
        "        self.magnitude = magnitude\n",
        "\n",
        "    def __call__(self, img):\n",
        "        width, height = img.size\n",
        "        x_min = int(random.uniform(-self.magnitude, self.magnitude) * width)\n",
        "        y_min = int(random.uniform(-self.magnitude, self.magnitude) * height)\n",
        "        x_max = width + int(random.uniform(-self.magnitude, self.magnitude) * width)\n",
        "        y_max = height + int(random.uniform(-self.magnitude, self.magnitude) * height)\n",
        "\n",
        "        # Ensure the bounding box doesn't go out of bounds\n",
        "        x_min = max(0, x_min)\n",
        "        y_min = max(0, y_min)\n",
        "        x_max = min(width, x_max)\n",
        "        y_max = min(height, y_max)\n",
        "\n",
        "        # Apply the bounding box jitter\n",
        "        img = F.crop(img, y_min, x_min, y_max - y_min, x_max - x_min)\n",
        "        img = F.resize(img, (height, width))  # Resize back to original size\n",
        "\n",
        "        return img"
      ],
      "metadata": {
        "id": "Sag53d_1FgXe"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EarlyStopping:\n",
        "    def __init__(self, patience=5, delta=0, path='checkpoint.pt'):\n",
        "        self.patience = patience\n",
        "        self.delta = delta\n",
        "        self.path = path\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "\n",
        "    def __call__(self, val_loss, model, epoch):\n",
        "        if self.best_score is None:\n",
        "            self.best_score = val_loss\n",
        "            self.save_checkpoint(val_loss, model, epoch)\n",
        "        elif val_loss > self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = val_loss\n",
        "            self.save_checkpoint(val_loss, model, epoch)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model, epoch):\n",
        "        state = {\n",
        "            'net': model.state_dict(),\n",
        "            'epoch': epoch,\n",
        "        }\n",
        "        torch.save(state, self.path)\n",
        "        self.best_score = val_loss"
      ],
      "metadata": {
        "id": "jd8Id-w0FitN"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "root_path = os.path.join(drive_dir, \"architectures\", 'FaceNet_binary')\n",
        "os.makedirs(root_path, exist_ok=True)\n",
        "os.makedirs(os.path.join(root_path, 'intermediate_checkpoints'), exist_ok=True)\n",
        "print(root_path)\n",
        "IMAGE_SHAPE = (3, 160, 160)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1p3FBjVFnRy",
        "outputId": "99208680-48e5-4b3e-a6bc-6b821daca7fa"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/architectures/FaceNet_binary\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from facenet_pytorch import MTCNN, InceptionResnetV1, fixed_image_standardization, training\n",
        "batch_size = 128\n",
        "max_learning_rate = 0.001\n",
        "weight_decay = 1e-4\n",
        "epochs = 50\n",
        "\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandAugment(2, 22),\n",
        "    RandomBoundingBoxJitter(0.45),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "])\n",
        "\n",
        "# Normalize the test set same as training set without augmentation\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "])\n",
        "\n",
        "trainset = AgeDataset(\n",
        "    image_paths=X_train,\n",
        "    labels=y_train,\n",
        "    resize=IMAGE_SHAPE,\n",
        "    augmentations=transform_train,\n",
        ")\n",
        "\n",
        "testset = AgeDataset(\n",
        "    image_paths=X_test,\n",
        "    labels=y_test,\n",
        "    resize=IMAGE_SHAPE,\n",
        "    augmentations=transform_test,\n",
        ")\n",
        "\n",
        "# dataloaders - creating batches and shuffling the data\n",
        "trainloader = torch.utils.data.DataLoader(\n",
        "    trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "testloader = torch.utils.data.DataLoader(\n",
        "    testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "# device - cpu or gpu?\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# loss criterion\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# model\n",
        "model = InceptionResnetV1(\n",
        "    classify=True,\n",
        "    pretrained='vggface2',\n",
        "    num_classes=len(classes)).to(device)\n",
        "\n",
        "# optimizer and scheduler\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=max_learning_rate)\n",
        "scheduler = OneCycleLR(optimizer, max_lr=max_learning_rate, epochs=epochs, steps_per_epoch=len(trainloader))\n"
      ],
      "metadata": {
        "id": "Ubwsera-Fvt4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "2cf2fbaea71949bd927a19827d15b990",
            "cbb0af92f68b4e1199a0b45461a3971e",
            "fb5f727b33824b36b0e0a2f992476ac2",
            "65751edfaa674eba9d65ab1053979ada",
            "fa2e735205314513b92cba174e9ef26d",
            "cbea868f474c43fd8cf4b286515af143",
            "a4d6e2051da5419b8f8f1b2eaa9f2d8b",
            "05060865dc8641ccb35a56222c54cfff",
            "4012dcaec1e4495ca1c0663bba916580",
            "02bc43624a6f464da519d14b1e122bca",
            "43069b42f6a04baba3113e5965f377c7"
          ]
        },
        "outputId": "c1b43590-0d1b-43a2-a097-c9414fb72ce7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/107M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2cf2fbaea71949bd927a19827d15b990"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_accuracy(model, dataloader, device):\n",
        "    model.eval() # put in evaluation mode\n",
        "    total_correct = 0\n",
        "    total_images = 0\n",
        "    confusion_matrix = np.zeros([len(classes),len(classes)], int)\n",
        "    with torch.no_grad():\n",
        "        for data in dataloader:\n",
        "            images, labels = data\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            # import pdb; pdb.set_trace()\n",
        "            total_images += labels.size(0)\n",
        "            total_correct += (predicted == labels).sum().item()\n",
        "            for i, l in enumerate(labels):\n",
        "                confusion_matrix[l.item(), predicted[i].item()] += 1\n",
        "\n",
        "    model_accuracy = total_correct / total_images * 100\n",
        "    return model_accuracy, confusion_matrix"
      ],
      "metadata": {
        "id": "SBsuLlqCHYgW"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_acc = 0\n",
        "counter = 0"
      ],
      "metadata": {
        "id": "ORnoe0MiHaXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training loop\n",
        "loss_list = []\n",
        "train_acc_list = []\n",
        "test_acc_list = []\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    model.train()  # put in training mode\n",
        "    running_loss = 0.0\n",
        "    epoch_time = time.time()\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "        # send them to device\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = model(inputs)  # forward pass\n",
        "        loss = criterion(outputs, labels)  # calculate the loss\n",
        "        # always the same 3 steps\n",
        "        optimizer.zero_grad()  # zero the parameter gradients\n",
        "        loss.backward()  # backpropagation\n",
        "        optimizer.step()  # update parameters\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.data.item()\n",
        "\n",
        "    # Normalizing the loss by the total number of train batches\n",
        "    running_loss /= len(trainloader)\n",
        "\n",
        "    # Calculate training/test set accuracy of the existing model\n",
        "    train_accuracy, _ = calculate_accuracy(model, trainloader, device)\n",
        "    test_accuracy, _ = calculate_accuracy(model, testloader, device)\n",
        "\n",
        "    # append the losses\n",
        "    loss_list.append(running_loss)\n",
        "    train_acc_list.append(train_accuracy)\n",
        "    test_acc_list.append(test_accuracy)\n",
        "\n",
        "    # modify learning rate\n",
        "    scheduler.step()\n",
        "\n",
        "    # save every 5 models\n",
        "    # we comment because the model stopped before 20 epochs, so need to train for full 50\n",
        "    #if epoch % 5 == 0:\n",
        "     # print('==> Saving model ...')\n",
        "      #state = {\n",
        "       #   'net': model.state_dict(),\n",
        "        #  'epoch': epoch,\n",
        "      #}\n",
        "\n",
        "      #torch.save(state, os.path.join(root_path, 'intermediate_checkpoints', f'model_epoch_{epoch}.pth'))\n",
        "\n",
        "    # compute validation loss to check if we should stop\n",
        "    model.eval()  # switch to evaluation mode\n",
        "    test_loss = 0.0\n",
        "    total_test_samples = 0\n",
        "\n",
        "    with torch.no_grad():  # No need to compute gradients during validation\n",
        "      for data in testloader:\n",
        "        inputs, labels = data\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Update validation loss and total samples\n",
        "        test_loss += loss.item() * inputs.size(0)\n",
        "        total_test_samples += inputs.size(0)\n",
        "\n",
        "    # Calculate average validation loss\n",
        "    test_loss /= total_test_samples\n",
        "\n",
        "    log = \"Epoch: {} | Training Loss: {:.4f} | Test Loss: {:.4f} | Training accuracy: {:.3f}% | Test accuracy: {:.3f}% | \".format(epoch, running_loss, test_loss, train_accuracy, test_accuracy)\n",
        "    epoch_time = time.time() - epoch_time\n",
        "    log += \"Epoch Time: {:.2f} secs\".format(epoch_time)\n",
        "    print(log)\n",
        "\n",
        "    state = {\n",
        "        'net': model.state_dict(),\n",
        "        'epoch': epoch,\n",
        "    }\n",
        "    torch.save(state, os.path.join(root_path, f'model_{epoch}.pth'))\n",
        "\n",
        "    if test_accuracy > best_acc:\n",
        "      counter = 0\n",
        "      best_acc = test_accuracy\n",
        "      torch.save(state, os.path.join(root_path, f'best_model.pth'))\n",
        "    else:\n",
        "      counter += 1\n",
        "\n",
        "    if counter > 5:\n",
        "      break\n",
        "\n",
        "print('==> Finished Training ...')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjavEUjeHTBf",
        "outputId": "45aaad20-d5e0-454d-e234-b9abb864c831"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 | Training Loss: 0.6318 | Test Loss: 0.5477 | Training accuracy: 87.020% | Test accuracy: 90.896% | Epoch Time: 67.39 secs\n",
            "Epoch: 2 | Training Loss: 0.5307 | Test Loss: 0.5783 | Training accuracy: 90.759% | Test accuracy: 93.018% | Epoch Time: 66.65 secs\n",
            "Epoch: 3 | Training Loss: 0.4881 | Test Loss: 0.5206 | Training accuracy: 87.821% | Test accuracy: 90.039% | Epoch Time: 66.78 secs\n",
            "Epoch: 4 | Training Loss: 0.4266 | Test Loss: 0.2200 | Training accuracy: 91.257% | Test accuracy: 94.005% | Epoch Time: 67.67 secs\n",
            "Epoch: 5 | Training Loss: 0.4219 | Test Loss: 0.2604 | Training accuracy: 90.857% | Test accuracy: 94.042% | Epoch Time: 67.10 secs\n",
            "Epoch: 6 | Training Loss: 0.3697 | Test Loss: 0.4036 | Training accuracy: 91.876% | Test accuracy: 93.484% | Epoch Time: 66.62 secs\n",
            "Epoch: 7 | Training Loss: 0.3402 | Test Loss: 0.1650 | Training accuracy: 91.974% | Test accuracy: 94.433% | Epoch Time: 66.74 secs\n",
            "Epoch: 8 | Training Loss: 0.2940 | Test Loss: 0.1818 | Training accuracy: 91.508% | Test accuracy: 94.191% | Epoch Time: 66.56 secs\n",
            "Epoch: 9 | Training Loss: 0.3112 | Test Loss: 0.5017 | Training accuracy: 91.941% | Test accuracy: 94.247% | Epoch Time: 66.62 secs\n",
            "Epoch: 10 | Training Loss: 0.2986 | Test Loss: 0.1644 | Training accuracy: 92.193% | Test accuracy: 94.843% | Epoch Time: 66.95 secs\n",
            "Epoch: 11 | Training Loss: 0.2656 | Test Loss: 0.2139 | Training accuracy: 92.519% | Test accuracy: 94.731% | Epoch Time: 66.97 secs\n",
            "Epoch: 12 | Training Loss: 0.2541 | Test Loss: 0.1699 | Training accuracy: 92.584% | Test accuracy: 94.545% | Epoch Time: 66.26 secs\n",
            "Epoch: 13 | Training Loss: 0.2434 | Test Loss: 0.2283 | Training accuracy: 92.593% | Test accuracy: 94.526% | Epoch Time: 66.72 secs\n",
            "Epoch: 14 | Training Loss: 0.2413 | Test Loss: 0.1364 | Training accuracy: 92.868% | Test accuracy: 95.103% | Epoch Time: 66.14 secs\n",
            "Epoch: 15 | Training Loss: 0.2230 | Test Loss: 0.1374 | Training accuracy: 92.784% | Test accuracy: 94.992% | Epoch Time: 66.69 secs\n",
            "Epoch: 16 | Training Loss: 0.2230 | Test Loss: 0.1386 | Training accuracy: 93.003% | Test accuracy: 95.252% | Epoch Time: 66.94 secs\n",
            "Epoch: 17 | Training Loss: 0.2104 | Test Loss: 0.1232 | Training accuracy: 93.212% | Test accuracy: 95.364% | Epoch Time: 66.84 secs\n",
            "Epoch: 18 | Training Loss: 0.2040 | Test Loss: 0.1384 | Training accuracy: 93.091% | Test accuracy: 95.290% | Epoch Time: 67.13 secs\n",
            "Epoch: 19 | Training Loss: 0.2029 | Test Loss: 0.1316 | Training accuracy: 93.198% | Test accuracy: 95.457% | Epoch Time: 66.73 secs\n",
            "Epoch: 20 | Training Loss: 0.2056 | Test Loss: 0.1440 | Training accuracy: 93.254% | Test accuracy: 95.550% | Epoch Time: 66.86 secs\n",
            "Epoch: 21 | Training Loss: 0.1968 | Test Loss: 0.1271 | Training accuracy: 93.454% | Test accuracy: 95.457% | Epoch Time: 67.31 secs\n",
            "Epoch: 22 | Training Loss: 0.1952 | Test Loss: 0.1326 | Training accuracy: 93.184% | Test accuracy: 95.085% | Epoch Time: 66.87 secs\n",
            "Epoch: 23 | Training Loss: 0.1914 | Test Loss: 0.1185 | Training accuracy: 93.692% | Test accuracy: 95.699% | Epoch Time: 66.49 secs\n",
            "Epoch: 24 | Training Loss: 0.1858 | Test Loss: 0.1274 | Training accuracy: 93.799% | Test accuracy: 95.532% | Epoch Time: 67.37 secs\n",
            "Epoch: 25 | Training Loss: 0.1846 | Test Loss: 0.1273 | Training accuracy: 93.762% | Test accuracy: 95.494% | Epoch Time: 66.53 secs\n",
            "Epoch: 26 | Training Loss: 0.1836 | Test Loss: 0.1171 | Training accuracy: 93.729% | Test accuracy: 95.774% | Epoch Time: 66.96 secs\n",
            "Epoch: 27 | Training Loss: 0.1802 | Test Loss: 0.1208 | Training accuracy: 93.957% | Test accuracy: 95.718% | Epoch Time: 66.75 secs\n",
            "Epoch: 28 | Training Loss: 0.1794 | Test Loss: 0.1230 | Training accuracy: 94.004% | Test accuracy: 95.625% | Epoch Time: 66.92 secs\n",
            "Epoch: 29 | Training Loss: 0.1786 | Test Loss: 0.1228 | Training accuracy: 94.013% | Test accuracy: 95.420% | Epoch Time: 66.99 secs\n",
            "Epoch: 30 | Training Loss: 0.1749 | Test Loss: 0.1229 | Training accuracy: 94.046% | Test accuracy: 95.513% | Epoch Time: 66.72 secs\n",
            "Epoch: 31 | Training Loss: 0.1754 | Test Loss: 0.1134 | Training accuracy: 93.948% | Test accuracy: 96.034% | Epoch Time: 66.50 secs\n",
            "Epoch: 32 | Training Loss: 0.1746 | Test Loss: 0.1200 | Training accuracy: 94.209% | Test accuracy: 95.867% | Epoch Time: 67.04 secs\n",
            "Epoch: 33 | Training Loss: 0.1679 | Test Loss: 0.1239 | Training accuracy: 94.129% | Test accuracy: 95.755% | Epoch Time: 66.64 secs\n",
            "Epoch: 34 | Training Loss: 0.1665 | Test Loss: 0.1387 | Training accuracy: 94.143% | Test accuracy: 95.383% | Epoch Time: 66.37 secs\n",
            "Epoch: 35 | Training Loss: 0.1651 | Test Loss: 0.1185 | Training accuracy: 93.999% | Test accuracy: 95.587% | Epoch Time: 67.48 secs\n",
            "Epoch: 36 | Training Loss: 0.1665 | Test Loss: 0.1186 | Training accuracy: 94.334% | Test accuracy: 95.960% | Epoch Time: 67.04 secs\n",
            "Epoch: 37 | Training Loss: 0.1618 | Test Loss: 0.1233 | Training accuracy: 94.655% | Test accuracy: 95.494% | Epoch Time: 66.17 secs\n",
            "==> Finished Training ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = InceptionResnetV1(\n",
        "    classify=True,\n",
        "    pretrained='vggface2',\n",
        "    num_classes=len(classes)).to(device)\n",
        "\n",
        "# Load the saved model state dictionary\n",
        "checkpoint = torch.load(os.path.join(root_path, 'best_model.pth'))\n",
        "\n",
        "# Load the model state dictionary\n",
        "best_model.load_state_dict(checkpoint['net'])\n",
        "best_model.to(device)\n",
        "\n",
        "transform_testing_purposes = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "])\n",
        "\n",
        "trainset = AgeDataset(\n",
        "    image_paths=X_train,\n",
        "    labels=y_train,\n",
        "    resize=IMAGE_SHAPE,\n",
        "    augmentations=transform_testing_purposes,\n",
        ")\n",
        "\n",
        "testset = AgeDataset(\n",
        "    image_paths=X_test,\n",
        "    labels=y_test,\n",
        "    resize=IMAGE_SHAPE,\n",
        "    augmentations=transform_testing_purposes,\n",
        ")\n",
        "\n",
        "# Create a DataLoader for the training set without data augmentation\n",
        "trainloader_no_aug = torch.utils.data.DataLoader(\n",
        "    trainset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "testloader_for_testing = torch.utils.data.DataLoader(\n",
        "    testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "no_aug_train_acc, confusion_matrix_train = calculate_accuracy(best_model, trainloader_no_aug, device)\n",
        "test_acc, confusion_matrix_test = calculate_accuracy(best_model, testloader_for_testing, device)\n",
        "\n",
        "print(f\"Accuracy on Training Set: {no_aug_train_acc}%\")\n",
        "print(f\"Accuracy on Test Set: {test_acc}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FyilxLeQRJvi",
        "outputId": "2d5bda3e-951d-4694-bc3a-e14c5fc4417f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on Training Set: 97.38826815642459%\n",
            "Accuracy on Test Set: 96.03425805250419%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Create a DataLoader for the training set without data augmentation\n",
        "trainloader_no_aug = torch.utils.data.DataLoader(\n",
        "    trainset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "testloader_for_testing = torch.utils.data.DataLoader(\n",
        "    testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "# Function to get predictions from dataloader\n",
        "def get_predictions(model, dataloader, device):\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    true_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            predictions.extend(preds.cpu().numpy())\n",
        "            true_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    return predictions, true_labels\n",
        "\n",
        "# Get predictions for the training and test sets\n",
        "train_predictions, train_true_labels = get_predictions(best_model, trainloader_no_aug, device)\n",
        "test_predictions, test_true_labels = get_predictions(best_model, testloader_for_testing, device)\n",
        "\n",
        "# Generate classification report\n",
        "print(\"Classification Report for Training Set:\")\n",
        "print(classification_report(train_true_labels, train_predictions, digits=4))\n",
        "\n",
        "print(\"Classification Report for Test Set:\")\n",
        "print(classification_report(test_true_labels, test_predictions, digits=4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXOXC5OVS8Kb",
        "outputId": "fa2495be-b0a7-48b4-c42a-01394dba0549"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report for Training Set:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9461    0.7959    0.8645      2249\n",
            "           1     0.9766    0.9947    0.9855     19231\n",
            "\n",
            "    accuracy                         0.9739     21480\n",
            "   macro avg     0.9613    0.8953    0.9250     21480\n",
            "weighted avg     0.9734    0.9739    0.9729     21480\n",
            "\n",
            "Classification Report for Test Set:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8975    0.7011    0.7872       562\n",
            "           1     0.9659    0.9906    0.9781      4809\n",
            "\n",
            "    accuracy                         0.9603      5371\n",
            "   macro avg     0.9317    0.8459    0.8827      5371\n",
            "weighted avg     0.9588    0.9603    0.9582      5371\n",
            "\n"
          ]
        }
      ]
    }
  ]
}