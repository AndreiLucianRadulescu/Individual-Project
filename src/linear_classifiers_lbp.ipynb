{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now it's time to test how the LBP (Local Binary Patterns) method works when extracting features from images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import local_binary_pattern\n",
    "from skimage import io, color, feature\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "pickle_file_path = './dataframe.pkl'\n",
    "all_images_path = '../data/processed/all_images'\n",
    "all_images = os.listdir(all_images_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_lbp(imagepath, num_points, radius):\n",
    "    rgb_image = cv2.imread(f\"{all_images_path}/{imagepath}\")\n",
    "    gray_image = cv2.cvtColor(rgb_image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    lbp = local_binary_pattern(gray_image, num_points, radius, method='uniform')\n",
    "    (histogram, _) = np.histogram(lbp.ravel(), bins=np.arange(0, num_points+3), range = (0, num_points+2))\n",
    "    \n",
    "    histogram = histogram.astype(\"float\")\n",
    "    return histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16384.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "P = 16\n",
    "R = 2\n",
    "x = extract_lbp(all_images[0], P, R)\n",
    "print(sum(x))\n",
    "# Plot the histogram\n",
    "plt.bar(np.arange(0, P+2), x, align='center')\n",
    "plt.title('LBP Histogram')\n",
    "plt.xlabel('LBP Code')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After seeing how the LBP histogram looks, I will experiment with different normalisation techniques.\n",
    "For this part, I will choose the number of points to be 16, the radius to be 2, and I will perform training and validation on the first fold of the 5 folds performed for HOG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataframe.pkl', 'rb') as f:\n",
    "    hog_df = pickle.load(f)\n",
    "\n",
    "no_hog_df = hog_df.drop('hog_features', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26851/26851 [03:28<00:00, 128.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              name  age  \\\n",
      "0                       000002.jpg   80   \n",
      "1                       000003.jpg   50   \n",
      "2                       000004.jpg   17   \n",
      "3                       000005.jpg   27   \n",
      "4                       000006.jpg   24   \n",
      "...                            ...  ...   \n",
      "26846  9_1_0_20170110224621441.jpg    9   \n",
      "26847  9_1_0_20170117172655681.jpg    9   \n",
      "26848  9_1_0_20170117180006484.jpg    9   \n",
      "26849  9_1_1_20170109201837354.jpg    9   \n",
      "26850  9_1_1_20170117105556810.jpg    9   \n",
      "\n",
      "                                              lbp_p16_r2  \n",
      "0      [703.0, 449.0, 606.0, 598.0, 482.0, 594.0, 793...  \n",
      "1      [775.0, 548.0, 524.0, 472.0, 449.0, 593.0, 751...  \n",
      "2      [537.0, 324.0, 421.0, 517.0, 451.0, 643.0, 100...  \n",
      "3      [594.0, 365.0, 407.0, 473.0, 513.0, 693.0, 970...  \n",
      "4      [235.0, 234.0, 262.0, 286.0, 381.0, 698.0, 107...  \n",
      "...                                                  ...  \n",
      "26846  [478.0, 291.0, 381.0, 399.0, 515.0, 753.0, 108...  \n",
      "26847  [543.0, 248.0, 366.0, 554.0, 623.0, 741.0, 109...  \n",
      "26848  [276.0, 239.0, 300.0, 391.0, 432.0, 673.0, 100...  \n",
      "26849  [754.0, 469.0, 424.0, 401.0, 470.0, 643.0, 835...  \n",
      "26850  [281.0, 168.0, 269.0, 367.0, 425.0, 678.0, 107...  \n",
      "\n",
      "[26851 rows x 3 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "no_hog_df['lbp_p16_r2'] = no_hog_df['name'].progress_apply(lambda x: extract_lbp(x, 16, 2))\n",
    "print(no_hog_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./dataframe_lbp_16p_2r.pkl', 'wb') as f:\n",
    "    pickle.dump(no_hog_df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_histogram(histogram, method):\n",
    "    if method == 'L1':\n",
    "        # L1 normalization (sum of absolute values)\n",
    "        norm_factor = np.sum(np.abs(histogram))\n",
    "    elif method == 'L2':\n",
    "        # L2 normalization (Euclidean norm)\n",
    "        norm_factor = np.sqrt(np.sum(histogram ** 2))\n",
    "    elif method == 'max':\n",
    "        # Max normalization (divide by maximum value)\n",
    "        norm_factor = np.max(histogram)\n",
    "    elif method == 'sum':\n",
    "        # Sum normalization (divide by sum of values)\n",
    "        norm_factor = np.sum(histogram)\n",
    "    else:\n",
    "        norm_factor = np.sum(np.abs(histogram))\n",
    "\n",
    "    return histogram / norm_factor\n",
    "\n",
    "def get_class_dict(filename):\n",
    "    with open(filename, \"r\") as f:\n",
    "        class_dict = json.load(f)\n",
    "    \n",
    "    return class_dict\n",
    "\n",
    "# Function that gets the label for an age, given a label dictionary\n",
    "def get_class(age, class_dict):\n",
    "    for label, age_interval in class_dict.items():\n",
    "        if age >= age_interval[0] and age <= age_interval[1]:\n",
    "            return label\n",
    "\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "multilabel_dict = get_class_dict(\"age_intervals_one.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working for norm = L1\n",
      "Working for norm = L1\n",
      "Working for norm = L1\n",
      "Working for norm = L1\n",
      "Working for norm = L1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [01:54<05:43, 114.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy for norm = L1 is: 0.44017690875232773\n",
      "Working for norm = L2\n",
      "Working for norm = L2\n",
      "Working for norm = L2\n",
      "Working for norm = L2\n",
      "Working for norm = L2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [03:50<03:50, 115.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy for norm = L2 is: 0.4395251396648045\n",
      "Working for norm = max\n",
      "Working for norm = max\n",
      "Working for norm = max\n",
      "Working for norm = max\n",
      "Working for norm = max\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [05:53<01:58, 118.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy for norm = max is: 0.4400837988826815\n",
      "Working for norm = sum\n",
      "Working for norm = sum\n",
      "Working for norm = sum\n",
      "Working for norm = sum\n",
      "Working for norm = sum\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [08:14<00:00, 123.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy for norm = sum is: 0.44017690875232773\n",
      "Therefore, best normalisation is: L1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "norms = ['L1', 'L2', 'max', 'sum']\n",
    "norms_accuracies = []\n",
    "\n",
    "for i in tqdm(range(len(norms))):\n",
    "    norm = norms[i]\n",
    "    cv_accuracies = []\n",
    "    for j in range(5):\n",
    "        # load the fold indices\n",
    "        with open(f'./fold_data/fold_{j}.json', 'r') as f:\n",
    "            fold_data = json.load(f)\n",
    "        \n",
    "        # get the train and validation folds\n",
    "        X_fold_train = np.vstack(np.array([item for item in no_hog_df['lbp_p16_r2']])[fold_data['train']])\n",
    "        y_fold_train = np.array([get_class(x, multilabel_dict) for x in no_hog_df['age']])[fold_data['train']]\n",
    "        X_fold_val = np.vstack(np.array([item for item in no_hog_df['lbp_p16_r2']])[fold_data['val']])\n",
    "        y_fold_val = np.array([get_class(x, multilabel_dict) for x in no_hog_df['age']])[fold_data['val']]\n",
    "                \n",
    "        # compute normalised LBP histograms\n",
    "        X_fold_train_normalised = np.array([normalise_histogram(row, method=norm) for row in X_fold_train])\n",
    "        X_fold_val_normalised = np.array([normalise_histogram(row, method=norm) for row in X_fold_val])\n",
    "        print(f\"Working for norm = {norm}\")\n",
    "        \n",
    "        svm_classifier = SVC()\n",
    "        svm_classifier.fit(X_fold_train_normalised, y_fold_train)\n",
    "        predictions = svm_classifier.predict(X_fold_val_normalised)\n",
    "        acc = accuracy_score(y_fold_val, predictions)\n",
    "        cv_accuracies.append(acc)\n",
    "    \n",
    "    cv_acc = np.mean(cv_accuracies)\n",
    "    print(f'CV Accuracy for norm = {norm} is: {cv_acc}')\n",
    "    norms_accuracies.append((norm, cv_acc))\n",
    "\n",
    "print(f'Therefore, best normalisation is: {sorted(norms_accuracies, reverse=True, key = lambda x: x[1])[0][0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Although there is no much difference in normalisations, sum normalisation and L1 norm perform the best (because all values are positive, so obviously). Therefore, I will choose the sum norm. Now onto the best choice for the number of points and radius."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26851/26851 [02:19<00:00, 192.45it/s]\n",
      "100%|██████████| 26851/26851 [02:32<00:00, 176.41it/s]\n",
      "100%|██████████| 26851/26851 [04:11<00:00, 106.88it/s]\n",
      "100%|██████████| 26851/26851 [03:23<00:00, 131.72it/s]\n",
      "100%|██████████| 26851/26851 [05:20<00:00, 83.67it/s]\n",
      "100%|██████████| 26851/26851 [05:09<00:00, 86.66it/s]\n",
      "100%|██████████| 6/6 [22:59<00:00, 229.94s/it]\n"
     ]
    }
   ],
   "source": [
    "p_r_pairs = [(8, 1), (8, 2), (16, 1), (16, 2), (24, 1), (24, 2)]\n",
    "for i in tqdm(range(len(p_r_pairs))):\n",
    "    p, r = p_r_pairs[i]\n",
    "    with open('dataframe.pkl', 'rb') as f:\n",
    "        hog_df = pickle.load(f)\n",
    "\n",
    "    no_hog_df = hog_df.drop('hog_features', axis=1)\n",
    "    no_hog_df[f'lbp_{p}p_{r}r'] = no_hog_df['name'].progress_apply(lambda x: extract_lbp(x, p, r))\n",
    "\n",
    "    with open(f'./dataframe_lbp_{p}p_{r}r.pkl', 'wb') as f:\n",
    "        pickle.dump(no_hog_df, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that all lbp features have been saved, we can go ah ead and perform cross validation with a simple SVM classifier, on the 5 folds, to see which parameter setting is the best. Before fitting the SVM, we need to normalise the vectors using L1 norm, as stated previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently working on LBP with p=8 and r=1\n",
      "Accuracy for fold=0 is: 0.4136405959031657.\n",
      "Accuracy for fold=1 is: 0.43854748603351956.\n",
      "Accuracy for fold=2 is: 0.430633147113594.\n",
      "Accuracy for fold=3 is: 0.42481378026070765.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [01:32<07:44, 92.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for fold=4 is: 0.44297020484171323.\n",
      "Currently working on LBP with p=8 and r=2\n",
      "Accuracy for fold=0 is: 0.41480446927374304.\n",
      "Accuracy for fold=1 is: 0.4411080074487896.\n",
      "Accuracy for fold=2 is: 0.43226256983240224.\n",
      "Accuracy for fold=3 is: 0.42877094972067037.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [03:04<06:07, 91.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for fold=4 is: 0.44646182495344505.\n",
      "Currently working on LBP with p=16 and r=1\n",
      "Accuracy for fold=0 is: 0.41620111731843573.\n",
      "Accuracy for fold=1 is: 0.44064245810055863.\n",
      "Accuracy for fold=2 is: 0.43226256983240224.\n",
      "Accuracy for fold=3 is: 0.4266759776536313.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [04:57<05:04, 101.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for fold=4 is: 0.44553072625698326.\n",
      "Currently working on LBP with p=16 and r=2\n",
      "Accuracy for fold=0 is: 0.42202048417132215.\n",
      "Accuracy for fold=1 is: 0.4436685288640596.\n",
      "Accuracy for fold=2 is: 0.44273743016759776.\n",
      "Accuracy for fold=3 is: 0.438780260707635.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [06:49<03:31, 105.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for fold=4 is: 0.4536778398510242.\n",
      "Currently working on LBP with p=24 and r=1\n",
      "Accuracy for fold=0 is: 0.4180633147113594.\n",
      "Accuracy for fold=1 is: 0.441340782122905.\n",
      "Accuracy for fold=2 is: 0.4338919925512104.\n",
      "Accuracy for fold=3 is: 0.4278398510242086.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5/6 [09:03<01:55, 115.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for fold=4 is: 0.44646182495344505.\n",
      "Currently working on LBP with p=24 and r=2\n",
      "Accuracy for fold=0 is: 0.4264432029795158.\n",
      "Accuracy for fold=1 is: 0.44273743016759776.\n",
      "Accuracy for fold=2 is: 0.4415735567970205.\n",
      "Accuracy for fold=3 is: 0.4408752327746741.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [11:11<00:00, 111.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for fold=4 is: 0.45344506517690875.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lbp_prtweak_models = {}\n",
    "best_norm = \"L1\"\n",
    "\n",
    "for i in tqdm(range(len(p_r_pairs))):\n",
    "    # get corresponding dataframe for given p and r values\n",
    "    p, r = p_r_pairs[i]\n",
    "    with open(f'./dataframe_lbp_{p}p_{r}r.pkl', 'rb') as f:\n",
    "        df = pickle.load(f)\n",
    "    \n",
    "    cv_accuracies = []\n",
    "    print(f'Currently working on LBP with p={p} and r={r}')\n",
    "\n",
    "    # iterate through all 5 folds for CV\n",
    "    for j in range(5):\n",
    "        with open(f'./fold_data/fold_{j}.json') as f:\n",
    "            fold_data = json.load(f)\n",
    "        \n",
    "        # get folds from indices\n",
    "        X_fold_train = np.vstack(np.array([item for item in df[f'lbp_{p}p_{r}r']])[fold_data['train']])\n",
    "        y_fold_train = np.array([get_class(x, multilabel_dict) for x in df['age']])[fold_data['train']]\n",
    "        X_fold_val = np.vstack(np.array([item for item in df[f'lbp_{p}p_{r}r']])[fold_data['val']])\n",
    "        y_fold_val = np.array([get_class(x, multilabel_dict) for x in df['age']])[fold_data['val']]\n",
    "\n",
    "        # normalise LBP vectors\n",
    "        X_fold_train_normalised = np.array([normalise_histogram(row, method=best_norm) for row in X_fold_train])\n",
    "        X_fold_val_normalised = np.array([normalise_histogram(row, method=best_norm) for row in X_fold_val])\n",
    "\n",
    "        # fit SVM and find accuracy\n",
    "        svm_classifier = SVC()\n",
    "        svm_classifier.fit(X_fold_train_normalised, y_fold_train)\n",
    "        predictions = svm_classifier.predict(X_fold_val_normalised)\n",
    "        acc = accuracy_score(y_fold_val, predictions)\n",
    "        cv_accuracies.append(acc)\n",
    "        print(f'Accuracy for fold={j} is: {acc}.')\n",
    "    \n",
    "    cv_accuracy = np.mean(cv_accuracies)\n",
    "    lbp_prtweak_models[f'Model_{i*5+j}'] = {'p': p, 'r':r, 'cv_accuracy': cv_accuracy}\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('lbp_models_cv_pandr.json', 'w') as f:\n",
    "    json.dump(lbp_prtweak_models, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Model_29', 24, 2, 0.44101489757914336)\n"
     ]
    }
   ],
   "source": [
    "best_parameter_setting = [[model, lbp_prtweak_models[model]['cv_accuracy']] for model in lbp_prtweak_models]\n",
    "best_parameter_setting = sorted(best_parameter_setting, key=lambda x: x[1], reverse=True)[0][0]\n",
    "best_parameter_setting = (best_parameter_setting, lbp_prtweak_models[best_parameter_setting]['p'], \n",
    "                          lbp_prtweak_models[best_parameter_setting]['r'], \n",
    "                          lbp_prtweak_models[best_parameter_setting]['cv_accuracy'])\n",
    "\n",
    "print(best_parameter_setting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Therefore, the best model has p=24 and r=2. Now onto hyperparameter tuning for the SVM model. As for HOG, I will be tuning C value and the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_p, best_r = best_parameter_setting[1:-1]\n",
    "kernels = ['rbf', 'linear', 'poly']\n",
    "C_values = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "os.makedirs('lbp_models', exist_ok=True)\n",
    "model_folder = './lbp_models'\n",
    "\n",
    "with open(f'./dataframe_lbp_{best_p}p_{best_r}r.pkl', 'rb') as f:\n",
    "        df = pickle.load(f)\n",
    "\n",
    "for C in C_values:\n",
    "    for kernel in kernels:\n",
    "        print(f'Currently computing CV accuracy for C={C} and kernel={kernel}.')\n",
    "        cv_accuracies = []\n",
    "        model_name = f'Model_C={C}_kernel={kernel}'\n",
    "        \n",
    "        for i in range(5):\n",
    "            with open(f'./fold_data/fold_{i}.json') as f:\n",
    "                fold_data = json.load(f)\n",
    "            \n",
    "            # get folds from indices\n",
    "            X_fold_train = np.vstack(np.array([item for item in df[f'lbp_{best_p}p_{best_r}r']])[fold_data['train']])\n",
    "            y_fold_train = np.array([get_class(x, multilabel_dict) for x in df['age']])[fold_data['train']]\n",
    "            X_fold_val = np.vstack(np.array([item for item in df[f'lbp_{best_p}p_{best_r}r']])[fold_data['val']])\n",
    "            y_fold_val = np.array([get_class(x, multilabel_dict) for x in df['age']])[fold_data['val']]\n",
    "\n",
    "            # normalise LBP vectors\n",
    "            X_fold_train_normalised = np.array([normalise_histogram(row, method=best_norm) for row in X_fold_train])\n",
    "            X_fold_val_normalised = np.array([normalise_histogram(row, method=best_norm) for row in X_fold_val])\n",
    "\n",
    "            # fit SVM and find accuracy\n",
    "            svm_classifier = SVC(C=C, kernel=kernel)\n",
    "            svm_classifier.fit(X_fold_train_normalised, y_fold_train)\n",
    "            predictions = svm_classifier.predict(X_fold_val_normalised)\n",
    "            acc = accuracy_score(y_fold_val, predictions)\n",
    "            cv_accuracies.append(acc)\n",
    "\n",
    "            report = classification_report(y_fold_val, predictions)\n",
    "            with open(f\"{model_folder}/{model_name}_classification_report_fold_{i}.txt\", 'w') as f:\n",
    "                f.write(report)\n",
    "\n",
    "            print(f'Accuracy for fold={i} is: {acc}.')\n",
    "        \n",
    "        cv_accuracy = np.mean(cv_accuracies)\n",
    "\n",
    "        print(f'CV Accuracy for model={model_name} is: {cv_accuracy}')\n",
    "\n",
    "        with open(f\"{model_folder}/{model_name}.pkl\", 'wb') as f:\n",
    "            pickle.dump(svm_classifier, f)\n",
    "\n",
    "        with open(f\"{model_folder}/cv_accuracies.txt\", 'a') as f:\n",
    "             f.write(f\"{model_name}_CVaccuracy={cv_accuracy}\\n\")\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_p, best_r = 24, 2\n",
    "with open(f'./dataframe_lbp_{best_p}p_{best_r}r.pkl', 'rb') as f:\n",
    "        df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'2': 7444, '1': 4434, '3': 3447, '0': 1115, '4': 493, '5': 251})\n",
      "Counter({'2': 7342, '1': 4536, '3': 3420, '0': 1095, '4': 520, '5': 271})\n",
      "Counter({'2': 7386, '1': 4545, '3': 3380, '0': 1106, '4': 508, '5': 259})\n",
      "Counter({'2': 7402, '1': 4500, '3': 3399, '0': 1112, '4': 499, '5': 272})\n",
      "Counter({'2': 7326, '1': 4565, '3': 3390, '0': 1132, '4': 512, '5': 259})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "for i in range(5):\n",
    "    with open(f'./fold_data/fold_{i}.json') as f:\n",
    "        fold_data = json.load(f)\n",
    "    \n",
    "    # get folds from indices\n",
    "    X_fold_train = np.vstack(np.array([item for item in df[f'lbp_{best_p}p_{best_r}r']])[fold_data['train']])\n",
    "    y_fold_train = np.array([get_class(x, multilabel_dict) for x in df['age']])[fold_data['train']]\n",
    "    X_fold_val = np.vstack(np.array([item for item in df[f'lbp_{best_p}p_{best_r}r']])[fold_data['val']])\n",
    "    y_fold_val = np.array([get_class(x, multilabel_dict) for x in df['age']])[fold_data['val']]\n",
    "\n",
    "    print(Counter(y_fold_train))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
